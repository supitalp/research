<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.26" />
  <meta name="author" content="Henri Rebecq">
  <meta name="description" content="PhD student">

  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/research/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.0/css/academicons.min.css" integrity="sha512-GGGNUPDhnG8LEAEDsjqYIQns+Gu8RBs4j5XGlxl7UfRaZBhCCm5jenJkeJL8uPuOXGqgl8/H1gjlWQDRjd3cUQ==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono">
  <link rel="stylesheet" href="/research/css/hugo-academic.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-84780527-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  <link rel="alternate" href="https://supitalp.github.io/research/index.xml" type="application/rss+xml" title="Henri Rebecq">
  <link rel="feed" href="https://supitalp.github.io/research/index.xml" type="application/rss+xml" title="Henri Rebecq">

  <link rel="icon" type="image/png" href="/research/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/research/img/apple-touch-icon.png">

  <link rel="canonical" href="https://supitalp.github.io/research/">

  

  <title>Henri Rebecq</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/research/">Henri Rebecq</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/research/#about" data-target="#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/research/#publications_selected" data-target="#publications_selected">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/research/#posts" data-target="#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/research/#teaching" data-target="#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/research/#contact" data-target="#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>



<span id="homepage" style="display: none"></span>



  
  
  <section id="about" class="home-section">
    <div class="container">
      



<div class="row" itemprop="author" itemscope itemtype="http://schema.org/Person" itemref="person-email person-telephone person-address">
  <div class="col-xs-12 col-md-4">
    <div id="profile">

      
      <div class="portrait" style="background-image: url('https://supitalp.github.io/research/img/portrait.jpg');"></div>
      <meta itemprop="image" content="https://supitalp.github.io/research/img/portrait.jpg">
      

      <div class="portrait-title">
        <h2 itemprop="name">Henri Rebecq</h2>
        <h3 itemprop="jobTitle">PhD student</h3>
        
        <h3 itemprop="worksFor" itemscope itemtype="http://schema.org/Organization">
          <a href="https://rpg.ifi.uzh.ch" target="_blank" itemprop="url">
            <span itemprop="name">Robotics and Perception Group, University of Zürich</span>
          </a>
        </h3>
        
      </div>

      <link itemprop="url" href="https://supitalp.github.io/research/">

      <ul class="social-icon" aria-hidden="true">
        
        
        <li>
          <a itemprop="sameAs" href="mailto:rebecq@ifi.uzh.ch" target="_blank">
            <i class="fa fa-envelope big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a itemprop="sameAs" href="https://scholar.google.co.uk/citations?user=zveWLBkAAAAJ" target="_blank">
            <i class="ai ai-google-scholar big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a itemprop="sameAs" href="https://www.linkedin.com/in/henri-rebecq-81bb9a97" target="_blank">
            <i class="fa fa-linkedin big-icon"></i>
          </a>
        </li>
        
        
        <li>
          <a itemprop="sameAs" href="//github.com/supitalp" target="_blank">
            <i class="fa fa-github big-icon"></i>
          </a>
        </li>
        
      </ul>

    </div>
  </div>
  <div class="col-xs-12 col-md-8" itemprop="description">

    

<h1 id="biography">Biography</h1>

<p>I am a PhD student at the <a href="http://rpg.ifi.uzh.ch" target="_blank">Robotics and Perception Group</a> directed by <a href="http://rpg.ifi.uzh.ch/people_scaramuzza.html" target="_blank">Davide Scaramuzza</a>, at University of Zürich.</p>

<p>I am specifically interested in <strong>event-based vision</strong> &mdash; using event cameras, such as the <a href="http://inilabs.com/products/dynamic-vision-sensors/" target="_blank">Dynamic Vision Sensor (DVS)</a>.</p>

<p>These cameras are novel, bio-inspired vision sensors that output pixel-level brightness changes instead of standard intensity frames. They offer significant advantages over standard cameras, namely:</p>

<ul>
<li>a very high dynamic range</li>
<li>no motion blur</li>
<li>a latency in the order of microseconds.</li>
</ul>

<p>However, because their output is composed of a sequence of <em>asynchronous events</em> rather than actual intensity images, traditional vision algorithms cannot be applied.</p>

<p>The goal of my research is to design novel algorithms that leverage the outstanding properties of event cameras to solve fundamental vision tasks for robotics &mdash; in particular <strong>SLAM</strong>, <strong>visual (inertial) odometry</strong> and <strong>mapping</strong> (3D reconstruction).</p>

<p>In the past, I have been working on <a href="https://supitalp.github.io/research/publication/benefit-large-fov-vo/" target="_blank">omnidirectional vision</a>, and I have also worked as a research engineer at <a href="http://www.video-stitch.com/" target="_blank">VideoStitch</a>.</p>

<p>I have graduated from <a href="https://www.telecom-paristech.fr/" target="_blank">Télécom ParisTech</a>, and I have studied <strong>machine learning</strong> and <strong>computer vision</strong> through the <a href="http://math.ens-paris-saclay.fr/version-francaise/formations/master-mva/" target="_blank">MVA M.Sc.</a> at ENS Cachan.</p>


    <div class="row">

      
      <div class="col-sm-5">
        <h3>Interests</h3>
        <ul class="ul-interests">
          
          <li>Event-based Vision</li>
          
          <li>SLAM</li>
          
          <li>Visual Odometry</li>
          
          <li>Visual Inertial Odometry</li>
          
        </ul>
      </div>
      

      
      <div class="col-sm-7">
        <h3>Education</h3>
        <ul class="ul-edu fa-ul">
          
          <li>
            <i class="fa-li fa fa-graduation-cap"></i>
            <div class="description">
              <p class="course">PhD student, 2015</p>
              <p class="institution">Robotics and Perception Group, University of Zürich</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa fa-graduation-cap"></i>
            <div class="description">
              <p class="course">M.Sc. Mathematics, Vision and Learning, 2014</p>
              <p class="institution">Ecole Normale Supérieure de Cachan</p>
            </div>
          </li>
          
          <li>
            <i class="fa-li fa fa-graduation-cap"></i>
            <div class="description">
              <p class="course">M.Sc.Eng., 2014</p>
              <p class="institution">Télécom ParisTech</p>
            </div>
          </li>
          
        </ul>
      </div>
      

    </div>
  </div>
</div>

    </div>
  </section>

  
  
  <section id="publications_selected" class="home-section">
    <div class="container">
      



<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Selected Publications</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    
    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://supitalp.github.io/research/publication/zevio/">
        <img src="/research/img/banners/zevio.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://supitalp.github.io/research/publication/zevio/" itemprop="url">Real-time Visual-Inertial Odometry for Event Cameras using Keyframe-based Nonlinear Optimization</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        We propose a novel, accurate tightly-coupled visual-inertial odometry pipeline for such cameras that leverages the outstanding properties of event cameras to estimate the camera ego-motion in challenging conditions, such as high-speed motion or high dynamic range scenes. The method tracks a set of features (extracted on the image plane) through time. To achieve that, we consider events in overlapping spatio-temporal windows and align them using the current camera motion and scene structure, yielding motion-compensated event frames. We then combine these feature tracks in a keyframe-based, visual-inertial odometry algorithm based on nonlinear optimization to estimate the camera’s 6-DOF pose and velocity.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Henri Rebecq, Timo Horstschaefer, Davide Scaramuzza
        
      </div>

      <div class="pub-publication">
        
        In <em>BMVC&rsquo;17</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/zevio/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/BMVC17_Rebecq.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://youtu.be/F3OFzsaPtvI">
  Video
</a>






      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://supitalp.github.io/research/publication/evo/">
        <img src="/research/img/banners/evo.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://supitalp.github.io/research/publication/evo/" itemprop="url">EVO: A Geometric Approach to Event-based 6-DOF Parallel Tracking and Mapping in Real-time</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        In this paper, we introduce the problem of Event-based Multi-View Stereo (EMVS) for event cameras and propose a solution to it. Unlike traditional MVS methods, which address the problem of estimating dense 3D structure from a set of known viewpoints, EMVS estimates semi-dense 3D structure from an event camera with known trajectory. Our algorithm is able to produce accurate, semi-dense depth maps and is computationally very efficient (runs in real-time on a CPU or even a smartphone processor).
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Henri Rebecq, Timo Horstschaefer, Guillermo Gallego, Davide Scaramuzza
        
      </div>

      <div class="pub-publication">
        
        In <em>RA-L&rsquo;17</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/evo/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/RAL16_EVO.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://youtu.be/bYqD2qZJlxE">
  Video
</a>






      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://supitalp.github.io/research/publication/dvs_data_paper/">
        <img src="/research/img/papers/dvs_data_paper.jpg" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://supitalp.github.io/research/publication/dvs_data_paper/" itemprop="url">The Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and SLAM</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        This presents the world&rsquo;s first collection of datasets with an event-based camera for high-speed robotics. The data also include intensity images, inertial measurements, and ground truth from a motion-capture system. An event-based camera is a revolutionary vision sensor with three key advantages: a measurement rate that is almost 1 million times faster than standard cameras, a latency of 1 microsecond, and a high dynamic range of 130 decibels (standard cameras only have 60 dB). These properties enable the design of a new class of algorithms for high-speed robotics, where standard cameras suffer from motion blur and high latency. All the data are released both as text files and binary (i.e., rosbag) files.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Elias Mueggler, Henri Rebecq, Guillermo Gallego, Tobi Delbruck, Davide Scaramuzza
        
      </div>

      <div class="pub-publication">
        
        In <em>IJRR&rsquo;17</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/dvs_data_paper/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/pdf/1610.08336.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=bVVBTQ7l36I">
  Video
</a>






      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://supitalp.github.io/research/publication/emvs/">
        <img src="/research/img/banners/emvs_banner.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://supitalp.github.io/research/publication/emvs/" itemprop="url">EMVS: Event-based Multi-View Stereo</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        In this paper, we introduce the problem of Event-based Multi-View Stereo (EMVS) for event cameras and propose a solution to it. Unlike traditional MVS methods, which address the problem of estimating dense 3D structure from a set of known viewpoints, EMVS estimates semi-dense 3D structure from an event camera with known trajectory. Our algorithm is able to produce accurate, semi-dense depth maps and is computationally very efficient (runs in real-time on a CPU or even a smartphone processor).
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Henri Rebecq, Guillermo Gallego, Davide Scaramuzza
        
      </div>

      <div class="pub-publication">
        
        In <em>BMVC&rsquo;16</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/emvs/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/BMVC16_Rebecq.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=EUX3Tfx0KKE">
  Video
</a>






      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://supitalp.github.io/research/publication/eb_6dof_tracking/">
        <img src="/research/img/banners/posetracking_banner.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://supitalp.github.io/research/publication/eb_6dof_tracking/" itemprop="url">Event-based, 6-DOF Camera Tracking for High-Speed Applications</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        In contrast to standard cameras, which produce frames at a fixed rate, event cameras respond asynchronously to pixel-level brightness changes, thus enabling the design of new algorithms for high-speed applications with latencies of microseconds. However, this advantage comes at a cost: because the output is composed by a sequence of events, traditional computer-vision algorithms are not applicable, so that a new paradigm shift is needed. We present an event-based approach for ego-motion estimation, which provides pose updates upon the arrival of each event, thus virtually eliminating latency. Our method is the first work addressing and demonstrating event-based pose tracking in six degrees-of-freedom (DOF) motions in realistic and natural scenes, and it is able to track high-speed motions. The method is successfully evaluated in both indoor and outdoor scenes.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Guillermo Gallego, Jon E.A. Lund, Elias Mueggler, Henri Rebecq, Tobi Delbruck, Davide Scaramuzza
        
      </div>

      <div class="pub-publication">
        
        In <em>arXiv&rsquo;16</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/eb_6dof_tracking/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/Arxiv16_Gallego.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=iZZ77F-hwzs">
  Video
</a>






      </div>

    </div>
  </div>
</div>

    
    <div class="pub-list-item" itemscope itemtype="http://schema.org/CreativeWork">
  <div class="row">

    

    <div class="col-md-12">
      <a href="https://supitalp.github.io/research/publication/benefit-large-fov-vo/">
        <img src="/research/img/banners/benefit_fov_vo_banner.png" class="pub-banner" itemprop="image">
      </a>
    </div>
    <div class="col-md-12">

    

      <h3 class="article-title" itemprop="name">
        <a href="https://supitalp.github.io/research/publication/benefit-large-fov-vo/" itemprop="url">Benefit of Large Field-of-View Cameras for Visual Odometry</a>
      </h3>

      <div class="pub-abstract" itemprop="text">
        
        The transition of visual-odometry technology from research demonstrators to commercial applications naturally raises the question: &ldquo;what is the optimal camera for vision-based motion estimation?&rdquo; This question is crucial as the choice of camera has a tremendous impact on the robustness and accuracy of the employed visual odometry algorithm. While many properties of a camera (e.g. resolution, frame-rate, global-shutter/rolling-shutter) could be considered, in this work we focus on evaluating the impact of the camera field-of-view (FoV) and optics (i.e., fisheye or catadioptric) on the quality of the motion estimate. Since the motion-estimation performance depends highly on the geometry of the scene and the motion of the camera, we analyze two common operational environments in mobile robotics: an urban environment and an indoor scene.
        
      </div>

      <div class="pub-authors" itemprop="author">
        
        Zichao Zhang, Henri Rebecq, Christian Forster, Davide Scaramuzza
        
      </div>

      <div class="pub-publication">
        
        In <em>ICRA&rsquo;16</em>
        
      </div>

      <div class="pub-links">
        



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/benefit-large-fov-vo/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/ICRA16_Zhang.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://youtu.be/6KXBoprGaR0">
  Video
</a>





<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/fov.html">
  Research page
</a>


      </div>

    </div>
  </div>
</div>

    
    

  </div>
</div>

    </div>
  </section>

  
  
  <section id="publications" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Recent Publications</h1>
    
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    
    <ul class="fa-ul">
      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Real-time Visual-Inertial Odometry for Event Cameras using Keyframe-based Nonlinear Optimization</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/zevio/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/BMVC17_Rebecq.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://youtu.be/F3OFzsaPtvI">
  Video
</a>





</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">EVO: A Geometric Approach to Event-based 6-DOF Parallel Tracking and Mapping in Real-time</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/evo/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/RAL16_EVO.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://youtu.be/bYqD2qZJlxE">
  Video
</a>





</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">The Event-Camera Dataset and Simulator: Event-based Data for Pose Estimation, Visual Odometry, and SLAM</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/dvs_data_paper/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="https://arxiv.org/pdf/1610.08336.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=bVVBTQ7l36I">
  Video
</a>





</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">EMVS: Event-based Multi-View Stereo</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/emvs/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/BMVC16_Rebecq.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=EUX3Tfx0KKE">
  Video
</a>





</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Event-based, 6-DOF Camera Tracking for High-Speed Applications</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/eb_6dof_tracking/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/Arxiv16_Gallego.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://www.youtube.com/watch?v=iZZ77F-hwzs">
  Video
</a>





</p>
</li>

      
      <li itemscope itemtype="http://schema.org/CreativeWork">
  <i class="fa-li fa fa-file-text-o pub-icon" aria-hidden="true"></i>
  <span itemprop="name">Benefit of Large Field-of-View Cameras for Visual Odometry</span>
  <p>



<a class="btn btn-primary btn-outline btn-xs" href="https://supitalp.github.io/research/publication/benefit-large-fov-vo/">
  Details
</a>


<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/docs/ICRA16_Zhang.pdf">
  PDF
</a>



<a class="btn btn-primary btn-outline btn-xs" href="https://youtu.be/6KXBoprGaR0">
  Video
</a>





<a class="btn btn-primary btn-outline btn-xs" href="http://rpg.ifi.uzh.ch/fov.html">
  Research page
</a>

</p>
</li>

      
    </ul>
    

  </div>
</div>

    </div>
  </section>

  
  
  <section id="posts" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">

    <h1>Recent Posts</h1>
    
    

  </div>
  <div class="col-xs-12 col-md-8">

    

    
      
        
        


<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://supitalp.github.io/research/post/new-paper-zevio/" itemprop="url">New paper accepted at BMVC17!</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2017-09-12 10:00:00 &#43;0000 UTC" itemprop="datePublished">
      Tue, Sep 12, 2017
    </time>
  </span>

  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/research/tags/visual-inertial-odometry">visual-inertial odometry</a
    >, 
    
    <a href="/research/tags/event-based-vision">event-based vision</a
    >, 
    
    <a href="/research/tags/real-time">real-time</a
    >
    
  </span>
  
  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    <p>Our paper <a href="https://supitalp.github.io/research/publication/zevio/" target="_blank">Real-time Visual-Inertial Odometry for Event Cameras using Keyframe-based Nonlinear Optimization</a> about visual-inertial odometry using an event camera has been accepted at BMVC&rsquo;17 for oral presentation (acceptance rate: 5.6 %)!</p>

<p>You can watch the video <a href="https://youtu.be/F3OFzsaPtvI" target="_blank">here</a>!</p>

    
  </div>
  <p class="read-more">
    <a href="https://supitalp.github.io/research/post/new-paper-zevio/" class="btn btn-primary btn-outline">
      CONTINUE READING
    </a>
  </p>
</div>

      
        
        


<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://supitalp.github.io/research/post/new-paper-evo/" itemprop="url">New paper accepted at RA-L and ICRA!</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2017-01-15 12:00:00 &#43;0000 UTC" itemprop="datePublished">
      Sun, Jan 15, 2017
    </time>
  </span>

  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/research/tags/visual-odometry">visual odometry</a
    >, 
    
    <a href="/research/tags/event-based-vision">event-based vision</a
    >, 
    
    <a href="/research/tags/slam">slam</a
    >
    
  </span>
  
  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    <p>Our paper <a href="https://supitalp.github.io/research/publication/evo/" target="_blank">EVO: A Geometric Approach to Event-based
6-DOF Parallel Tracking and Mapping in Real-time</a> has been accepted for publication in the Robotics and Automation Letters (RA-L), and for presentation at ICRA&rsquo;17!</p>

    
  </div>
  <p class="read-more">
    <a href="https://supitalp.github.io/research/post/new-paper-evo/" class="btn btn-primary btn-outline">
      CONTINUE READING
    </a>
  </p>
</div>

      
        
        


<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://supitalp.github.io/research/post/emvs_award/" itemprop="url">Best BMVC&#39;16 Industry Paper Award!</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2016-09-22 12:00:00 &#43;0000 UTC" itemprop="datePublished">
      Thu, Sep 22, 2016
    </time>
  </span>

  

  
  
  
  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    <p>Our paper <a href="https://supitalp.github.io/research/publication/emvs/" target="_blank">EMVS: Event-based Multi-View Stereo</a>, receives the BMVC&rsquo;16 Best Industry Paper Award!</p>

<p><img src="img/news/BMVCaward.jpg" alt="BMVC Best industry paper award" style="width: 400px;"/></p>

    
  </div>
  <p class="read-more">
    <a href="https://supitalp.github.io/research/post/emvs_award/" class="btn btn-primary btn-outline">
      CONTINUE READING
    </a>
  </p>
</div>

      
        
        


<div class="article-list-item" itemscope itemprop="blogPost">
  
  
  <h3 class="article-title" itemprop="name">
    <a href="https://supitalp.github.io/research/post/new-paper-emvs/" itemprop="url">New paper accepted at BMVC16!</a>
  </h3>
  

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2016-07-15 12:00:00 &#43;0000 UTC" itemprop="datePublished">
      Fri, Jul 15, 2016
    </time>
  </span>

  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/research/tags/multi-view-stereo">multi-view stereo</a
    >, 
    
    <a href="/research/tags/event-based-vision">event-based vision</a
    >, 
    
    <a href="/research/tags/3d-reconstruction">3d reconstruction</a
    >
    
  </span>
  
  

  

</div>

  <div class="article-style" itemprop="articleBody">
    
    <p>Our paper <a href="https://supitalp.github.io/research/publication/emvs/" target="_blank">EMVS: Event-based Multi-View Stereo</a> about monocular 3D reconstruction using an event camera has been accepted for oral presentation at BMVC&rsquo;16!</p>

    
  </div>
  <p class="read-more">
    <a href="https://supitalp.github.io/research/post/new-paper-emvs/" class="btn btn-primary btn-outline">
      CONTINUE READING
    </a>
  </p>
</div>

      
    

  </div>
</div>

    </div>
  </section>

  
  
  <section id="teaching" class="home-section">
    <div class="container">
      


<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Teaching</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    <p>I am a teaching assistant for the course <a href="http://www.vvz.ethz.ch/Vorlesungsverzeichnis/lerneinheitPre.do?semkez=2016W&amp;lang=en&amp;ansicht=ALLE&amp;lerneinheitId=110044" target="_blank">Vision Algorithms for Mobile Robotics</a> given at ETH Zürich.</p>

<p>I also occasionally supervise student projects. The list of projects currently available can be found <a href="http://rpg.ifi.uzh.ch/student_projects.php" target="_blank">here</a>.</p>

  </div>
</div>

    </div>
  </section>

  
  
  <section id="contact" class="home-section">
    <div class="container">
      




<div class="row">
  <div class="col-xs-12 col-md-4 section-heading">
    <h1>Contact</h1>
    
  </div>
  <div class="col-xs-12 col-md-8">
    

    <ul class="fa-ul" itemscope>

      
      <li>
        <i class="fa-li fa fa-envelope fa-2x" aria-hidden="true"></i>
        <span id="person-email" itemprop="email"><a href="mailto:rebecq@ifi.uzh.ch">rebecq@ifi.uzh.ch</a></span>
      </li>
      

      

      
      <li>
        <i class="fa-li fa fa-phone fa-2x" aria-hidden="true"></i>
        <span id="person-telephone" itemprop="telephone"><a href="tel:&#43;41%2044%20635%2043%2042">&#43;41 44 635 43 42</a></span>
      </li>
      

      

      

      
      <li>
        <i class="fa-li fa fa-map-marker fa-2x" aria-hidden="true"></i>
        <span id="person-address" itemprop="address">Robotics and Perception Group, Andreasstrasse 15, 8052 Zürich, Switzerland.</span>
      </li>
      

      

    </ul>

  </div>
</div>

    </div>
  </section>



<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2016 Henri Rebecq &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js" integrity="sha512-jGsMH83oKe9asCpkOVkBnUrDDTp8wl+adkB2D+//JtlxO4SrLoJdhbOysIFQJloQFD+C4Fl1rMsQZF76JjV0eQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js" integrity="sha512-iHzEu7GbSc705hE2skyH6/AlTpOfBmkx7nUqTLGzPYR+C1tRaItbRlJ7hT/D3YQ9SV0fqLKzp4XY9wKulTBGTw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js" integrity="sha512-Z5heTz36xTemt1TbtbfXtTq5lMfYnOkXM2/eWcTTiLU01+Sw4ku1i7vScDc8fWhrP2abz9GQzgKH5NGBLoYlAw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/plugins/ScrollToPlugin.min.js" integrity="sha512-CDeU7pRtkPX6XJtF/gcFWlEwyaX7mcAp5sO3VIu/ylsdR74wEw4wmBpD5yYTrmMAiAboi9thyBUr1vXRPA7t0Q==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    <script src="/research/js/hugo-academic.js"></script>
    

    
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    

  </body>
</html>

